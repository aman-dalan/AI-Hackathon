import google.generativeai as genai
import os

# All promts used in this project is generated by AI for the efficient result.
def execute_code(code, language):
    """
    Simulates code execution for testing.
    In a real app, this would run code in a sandbox (e.g., Docker, a third-party API).
    Returns (stdout, stderr).
    """
    if "def two_sum" in code.lower() and language == "python":
       
        return "Test 1: Passed\nTest 2: Passed\nAll tests passed!", ""
    elif "def" not in code.lower() and language == "python":
        return "", "Error: Syntax error or incomplete code. Expected 'def'."
    elif "int main()" in code.lower() and language == "cpp":
        return "C++ code executed. (Simulated output)", ""
    elif "public static void main" in code.lower() and language == "java":
        return "Java code executed. (Simulated output)", ""
    elif "function" in code.lower() and language == "javascript":
        return "JavaScript code executed. (Simulated output)", ""
    else:
        return "", "Error: Code execution failed or not yet supported for this code/language."

def analyze_code_with_llm(code, language, test_results, purpose="analysis"):
    model = genai.GenerativeModel("gemini-1.5-flash")

    prompt = f"""
    You are an AI Code Analyzer. Analyze the provided code, its execution results, and provide concise feedback.
    Purpose: {purpose} (e.g., "analysis" during iteration, "final evaluation" for submission).

    Language: {language}
    User Code:
    ```
    {code}
    ```
    Simulated Test Results:
    ```
    {test_results}
    ```
    
    Based on the results, provide:
    1.  **Summary:** A brief overview of whether tests passed or failed.
    2.  **Feedback:** If tests failed, suggest common reasons (e.g., syntax, logic error, edge cases). If tests passed but it's not optimal, suggest areas for improvement (e.g., time/space complexity).
    3.  **Optimization Hint (if applicable):** If tests passed but the code is not optimal, suggest how to make it optimal without providing the solution.
    4.  **Optimality Score (0-1):** A single number indicating how optimal the code is (0 for non-functional/very bad, 1 for optimal).

    Example Output:
    Summary: Tests failed.
    Feedback: It seems your loop condition might be off by one, or you're not handling an empty array case.
    Optimality Score: 0.2

    Example Optimal Output:
    Summary: All tests passed.
    Feedback: Your solution is correct and seems optimal for the given constraints.
    Optimality Score: 1.0
    """
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"Error in code_agent.analyze_code_with_llm: {e}")
        return "Analysis failed due to an internal error. Please check your code or try again."


def run_code_tests(code, language, final_submit=False):
    """
    Simulates running code tests and gets AI analysis.
    """
    stdout, stderr = execute_code(code, language)

    test_results_output = ""
    if stdout:
        test_results_output += f"STDOUT:\n{stdout}\n"
    if stderr:
        test_results_output += f"STDERR:\n{stderr}\n"

    if not stdout and not stderr:
        test_results_output = "No output. Check for compilation/runtime errors or print statements."

    purpose = "final evaluation" if final_submit else "analysis"
    ai_feedback = analyze_code_with_llm(code, language, test_results_output, purpose)

    optimality_score = 0.0
    optimal = False
    try:
        score_line = [line for line in ai_feedback.split('\n') if "Optimality Score:" in line]
        if score_line:
            optimality_score = float(score_line[0].split(":")[1].strip())
            if optimality_score >= 0.9:
                optimal = True
    except (ValueError, IndexError):
        pass

    return test_results_output, ai_feedback, optimal